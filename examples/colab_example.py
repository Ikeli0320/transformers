# Colab ç‰ˆæœ¬ - æ™ºèƒ½èªéŸ³è½‰éŒ„å·¥å…·
# åŸºæ–¼ faster-whisper çš„é«˜æ•ˆèƒ½ç‰ˆæœ¬

"""
Colab æ™ºèƒ½èªéŸ³è½‰éŒ„å·¥å…· (åŸºæ–¼ faster-whisper)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. å®‰è£ä¾è³´ï¼ˆåƒ…ç¬¬ä¸€æ¬¡åŸ·è¡Œéœ€è¦ï¼‰
2. å°‡éŸ³æª”æ‹–åˆ° Colab å·¦å´ Files æˆ–ç”¨ upload è¦–çª—ä¸Šå‚³
3. è‡ªå‹•è½‰æˆ 16 kHz / mono WAV âœ faster-Whisper âœ .txt
Author: Smart Audio Transcriber Team
License: MIT
"""

# â”€â”€ 1. å®‰è£ç³»çµ±èˆ‡ Python å¥—ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("Installing dependencies...")
import subprocess
import sys

def install(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--quiet", "--upgrade", package])

try:
    # Check if ffmpeg is installed by trying to run it
    subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True, text=True)
    print("ffmpeg is already installed.")
except (subprocess.CalledProcessError, FileNotFoundError):
    print("Installing ffmpeg...")
    subprocess.run(["apt-get", "-y", "update"], check=True)
    subprocess.run(["apt-get", "-y", "install", "-y", "ffmpeg"], check=True)
    print("ffmpeg installed.")

install("pydub")
install("faster-whisper")
install("psutil")
print("Dependencies installed/updated.")

# â”€â”€ 2. åŒ¯å…¥æ‰€éœ€å‡½å¼åº« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import tempfile
import torch
import psutil
from typing import Optional

from google.colab import files
from pydub import AudioSegment
from faster_whisper import WhisperModel

print("Libraries imported.")

# â”€â”€ 3. å·¥å…·å‡½å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_hardware():
    """æ™ºèƒ½ç¡¬é«”åµæ¸¬"""
    memory_gb = psutil.virtual_memory().total / (1024**3)
    cuda_available = torch.cuda.is_available()
    
    if cuda_available:
        device = "cuda"
        acceleration = "NVIDIA CUDA"
        compute_type = "float16"
        model_size = "large-v3"
    else:
        device = "cpu"
        acceleration = "CPU"
        compute_type = "int8"
        model_size = "medium"
    
    print(f"ğŸ”§ ç¡¬é«”åµæ¸¬:")
    print(f"   è¨˜æ†¶é«”: {memory_gb:.1f} GB")
    print(f"   åŠ é€Ÿæ–¹å¼: {acceleration}")
    print(f"   æ¨è–¦æ¨¡å‹: {model_size}")
    print(f"   è¨ˆç®—é¡å‹: {compute_type}")
    
    return {
        "device": device,
        "acceleration": acceleration,
        "compute_type": compute_type,
        "model_size": model_size,
        "memory_gb": memory_gb
    }

def convert_to_wav(src_path: str, target_sr: int = 16_000) -> str:
    """
    å°‡ä»»ä½•æ ¼å¼éŸ³æª”è½‰æˆ 16 kHzãƒ»monoãƒ»16-bit PCM WAVã€‚
    å›å‚³æš«å­˜æª”è·¯å¾‘ï¼Œè™•ç†éå¾Œè‡ªå‹•åˆªé™¤åŸæª”ä¸æœƒå½±éŸ¿ã€‚
    """
    print(f"Converting {src_path} to WAV...")
    audio = AudioSegment.from_file(src_path)
    audio = (
        audio.set_frame_rate(target_sr)
             .set_channels(1)
             .set_sample_width(2)      # 16-bit
    )
    # Using a temporary file that pydub can write to directly
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
        wav_path = tmp_file.name
    audio.export(wav_path, format="wav")
    print(f"Converted to WAV: {wav_path}")
    return wav_path

def transcribe_optimized(
    model: WhisperModel,
    wav_path: str,
    beam_size: int = 5,
    vad_filter: bool = True,
    vad_min_silence_duration_ms: int = 500
) -> dict:
    """
    ä½¿ç”¨ faster-Whisper è½‰éŒ„éŸ³æª”ã€‚
    """
    print("ğŸ”Š Transcribing with faster-whisper...")
    segments, info = model.transcribe(
        wav_path,
        beam_size=beam_size,
        vad_filter=vad_filter,
        vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms) if vad_filter else None
    )

    print(f"Detected language '{info.language}' with probability {info.language_probability}")
    print(f"Transcription duration: {info.duration}s (approx.)")

    # æ”¶é›†æ‰€æœ‰æ®µè½
    all_segments = list(segments)
    full_transcript = "".join(segment.text for segment in all_segments)
    
    # å‰µå»ºå¸¶æ™‚é–“æˆ³çš„çµæœ
    result = {
        "text": full_transcript,
        "chunks": []
    }
    
    for segment in all_segments:
        result["chunks"].append({
            "text": segment.text,
            "timestamp": [segment.start, segment.end]
        })

    return result

def save_transcript(result: dict, src_filename: str) -> str:
    """
    ä»¥ä¾†æºæª”åç‚ºåŸºç¤ï¼Œå„²å­˜ *_transcript.txtï¼Œä¸¦å›å‚³æª”åã€‚
    """
    stem = os.path.splitext(os.path.basename(src_filename))[0]
    txt_path = f"{stem}_transcript_smart.txt"
    
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write("=" * 60 + "\n")
        f.write("æ™ºèƒ½èªéŸ³è½‰éŒ„çµæœ (Smart Audio Transcriber)\n")
        f.write("=" * 60 + "\n")
        f.write(f"ä¾†æºæª”æ¡ˆ: {src_filename}\n")
        f.write(f"è½‰éŒ„æ™‚é–“: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}\n")
        f.write(f"æ¨¡å‹: faster-whisper\n")
        f.write("=" * 60 + "\n\n")
        
        # å®Œæ•´è½‰éŒ„çµæœ
        f.write("å®Œæ•´è½‰éŒ„çµæœ:\n")
        f.write("-" * 40 + "\n")
        f.write(result["text"])
        f.write("\n\n")
        
        # åˆ†æ®µæ™‚é–“æˆ³
        if result["chunks"]:
            f.write("åˆ†æ®µæ™‚é–“æˆ³:\n")
            f.write("-" * 40 + "\n")
            for chunk in result["chunks"]:
                start_time = chunk["timestamp"][0]
                end_time = chunk["timestamp"][1]
                text = chunk["text"]
                f.write(f"[{start_time:.1f}s - {end_time:.1f}s] {text}\n")
    
    print(f"ğŸ’¾ Saved transcript â†’ {txt_path}")
    return txt_path

# â”€â”€ 4. ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main_smart_transcriber(
    src_path: Optional[str] = None,
    model_size: Optional[str] = None,
    device: Optional[str] = None,
    compute_type: Optional[str] = None,
    beam_size: int = 5,
    vad_filter: bool = True,
    vad_min_silence_duration_ms: int = 500
) -> None:
    """
    æ™ºèƒ½èªéŸ³è½‰éŒ„ä¸»æµç¨‹
    """
    # 4-0 æ™ºèƒ½ç¡¬é«”åµæ¸¬
    hardware_info = detect_hardware()
    
    # ä½¿ç”¨åµæ¸¬çµæœæˆ–ç”¨æˆ¶æŒ‡å®šåƒæ•¸
    global_device = device or hardware_info["device"]
    global_compute_type = compute_type or hardware_info["compute_type"]
    global_model_size = model_size or hardware_info["model_size"]
    
    print(f"\nâ³ Loading faster-Whisper {global_model_size} model...")
    print(f"   Device: {global_device}")
    print(f"   Compute Type: {global_compute_type}")
    
    try:
        model = WhisperModel(global_model_size, device=global_device, compute_type=global_compute_type)
        print("âœ… Model loaded successfully.")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        print("ğŸ”„ Trying fallback configuration...")
        
        # å˜—è©¦å‚™ç”¨é…ç½®
        try:
            model = WhisperModel("medium", device="cpu", compute_type="int8")
            print("âœ… Fallback model loaded successfully.")
        except Exception as e2:
            print(f"âŒ Fallback failed: {e2}")
            return

    # 4-1 é¸å–éŸ³æª”
    if src_path is None:
        print("\nPlease upload an audio file.")
        uploads = files.upload()
        if not uploads:
            print("âŒ æ²’æœ‰æª”æ¡ˆï¼è«‹è‡³å°‘ä¸Šå‚³ä¸€å€‹éŸ³æª”ã€‚")
            return
        src_path = list(uploads.keys())[0]
        print(f"File '{src_path}' uploaded and saved to Colab environment.")

    if not os.path.exists(src_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{src_path}")
        return

    print(f"\nğŸ“¥ Source file: {src_path}")

    temp_wav_path = None
    try:
        # 4-2 è½‰æˆ WAV
        temp_wav_path = convert_to_wav(src_path)

        # 4-3 faster-whisper è½‰éŒ„
        result = transcribe_optimized(
            model,
            temp_wav_path,
            beam_size=beam_size,
            vad_filter=vad_filter,
            vad_min_silence_duration_ms=vad_min_silence_duration_ms
        )

        # 4-4 å„²å­˜ãƒ»ä¸‹è¼‰
        txt_path = save_transcript(result, src_path)
        print("\n==== è½‰éŒ„çµæœ ====\n")
        print(result["text"])
        print(f"\nğŸ“Š ç¸½å…± {len(result['chunks'])} å€‹æ®µè½")
        files.download(txt_path)

    except Exception as e:
        print(f"An error occurred during processing: {e}")
    finally:
        # Clean up the temporary WAV file
        if temp_wav_path and os.path.exists(temp_wav_path):
            try:
                os.remove(temp_wav_path)
                print(f"Cleaned up temporary WAV file: {temp_wav_path}")
            except OSError as e:
                print(f"Error deleting temporary file {temp_wav_path}: {e}")

# â”€â”€ 5. åŸ·è¡Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ™ºèƒ½èªéŸ³è½‰éŒ„ - è‡ªå‹•åµæ¸¬ç¡¬é«”ä¸¦å„ªåŒ–åƒæ•¸
print("ğŸ¯ æ™ºèƒ½èªéŸ³è½‰éŒ„å·¥å…· (Colab ç‰ˆæœ¬)")
print("=" * 50)

# åŸ·è¡Œæ™ºèƒ½è½‰éŒ„
main_smart_transcriber(
    src_path=None,  # ä½¿ç”¨ä¸Šå‚³è¦–çª—
    model_size=None,  # è‡ªå‹•é¸æ“‡
    device=None,  # è‡ªå‹•åµæ¸¬
    compute_type=None,  # è‡ªå‹•é¸æ“‡
    beam_size=5,
    vad_filter=True,
    vad_min_silence_duration_ms=500
)
