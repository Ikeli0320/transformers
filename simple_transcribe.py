#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆè½‰éŒ„ç¨‹å¼ - å°ˆæ³¨æ–¼è§£æ±ºè½‰éŒ„çµæœç©ºç™½å•é¡Œ
"""

import os
import torch
from transformers import pipeline
import subprocess
from datetime import datetime

def main():
    print("ğŸš€ å•Ÿå‹•ç°¡åŒ–ç‰ˆè½‰éŒ„ç¨‹å¼")
    print("=" * 50)
    
    # æª¢æŸ¥ç¡¬é«”
    print(f"ğŸ”§ CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"ğŸ”§ GPU: {torch.cuda.get_device_name(0)}")
    
    # è¼‰å…¥æ¨¡å‹
    print("ğŸ¤– è¼‰å…¥ Breeze-ASR-25 æ¨¡å‹...")
    model = pipeline(
        task="automatic-speech-recognition",
        model="MediaTek-Research/Breeze-ASR-25",
        device=0 if torch.cuda.is_available() else "cpu",
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        return_timestamps=True
    )
    print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    # å‰µå»ºè¼¸å‡ºæª”æ¡ˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"è½‰éŒ„çµæœ/result-source-{timestamp}.txt"
    
    # å¯«å…¥æ¨™é¡Œ
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("æ™ºèƒ½èªéŸ³è½‰éŒ„çµæœ (Breeze-ASR-25)\n")
        f.write("=" * 60 + "\n")
        f.write(f"æª”æ¡ˆ: source.aac\n")
        f.write(f"æ¨¡å‹: MediaTek-Research/Breeze-ASR-25\n")
        f.write(f"ç¡¬é«”: {'NVIDIA GPU' if torch.cuda.is_available() else 'CPU'}\n")
        f.write(f"è½‰éŒ„æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 60 + "\n\n")
        f.write("è½‰éŒ„çµæœ:\n")
        f.write("=" * 60 + "\n")
    
    print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {output_file}")
    
    # åˆ†æ®µè™•ç†
    segment_duration = 300  # 5åˆ†é˜ä¸€æ®µ
    total_duration = 4153  # ç¸½é•·åº¦ï¼ˆç§’ï¼‰
    num_segments = (total_duration // segment_duration) + 1
    
    print(f"ğŸ”¢ å°‡åˆ†ç‚º {num_segments} å€‹æ®µè½ï¼Œæ¯æ®µ {segment_duration} ç§’")
    
    for i in range(num_segments):
        start_time = i * segment_duration
        end_time = min((i + 1) * segment_duration, total_duration)
        
        print(f"ğŸ“Š è™•ç†æ®µè½ {i+1}/{num_segments}: {start_time}s - {end_time}s")
        
        try:
            # æå–éŸ³è¨Šæ®µè½
            segment_file = f"temp/segment_{i}.wav"
            cmd = [
                'ffmpeg', '-i', 'source.aac',
                '-ss', str(start_time),
                '-t', str(end_time - start_time),
                '-ar', '16000',
                '-ac', '1',
                '-y', segment_file
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                print(f"âš ï¸  æ®µè½ {i+1} æå–å¤±æ•—")
                continue
            
            # è½‰éŒ„
            print(f"ğŸ¯ è½‰éŒ„æ®µè½ {i+1}...")
            transcription_result = model(segment_file, return_timestamps=True)
            
            print(f"ğŸ” è½‰éŒ„çµæœ: {transcription_result}")
            
            # ä¿å­˜çµæœ
            with open(output_file, "a", encoding="utf-8") as f:
                if 'text' in transcription_result and transcription_result['text'].strip():
                    text = transcription_result['text'].strip()
                    f.write(f"[æ®µè½ {i+1}] {text}\n")
                    print(f"âœ… å·²ä¿å­˜: {text[:50]}...")
                else:
                    f.write(f"[æ®µè½ {i+1}] (ç„¡èªéŸ³å…§å®¹)\n")
                    print(f"âš ï¸  æ®µè½ {i+1} ç„¡èªéŸ³å…§å®¹")
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(segment_file):
                os.remove(segment_file)
                
        except Exception as e:
            print(f"âŒ æ®µè½ {i+1} è™•ç†å¤±æ•—: {e}")
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"[æ®µè½ {i+1}] è™•ç†å¤±æ•—: {str(e)}\n")
            continue
    
    print("=" * 50)
    print("ğŸ‰ è½‰éŒ„å®Œæˆï¼")
    print(f"ğŸ“ çµæœä¿å­˜åœ¨: {output_file}")

if __name__ == "__main__":
    main()
