#!/usr/bin/env python3
"""
ç°¡å–®çš„è½‰éŒ„æ¸¬è©¦ç¨‹å¼
æ¸¬è©¦ç¡¬é«”ã€æ¨¡å‹å’Œè½‰éŒ„åŠŸèƒ½æ˜¯å¦æ­£å¸¸
"""

import os
import torch
from transformers import pipeline
import subprocess

def test_hardware():
    """æ¸¬è©¦ç¡¬é«”é…ç½®"""
    print("ğŸ”§ ç¡¬é«”æ¸¬è©¦:")
    print(f"   CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   GPU åç¨±: {torch.cuda.get_device_name(0)}")
        print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB")
    print(f"   PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print()

def test_model_loading():
    """æ¸¬è©¦æ¨¡å‹è¼‰å…¥"""
    print("ğŸ¤– æ¨¡å‹è¼‰å…¥æ¸¬è©¦:")
    try:
        # æ¸¬è©¦ Breeze-ASR-25
        print("   è¼‰å…¥ Breeze-ASR-25...")
        model = pipeline(
            task="automatic-speech-recognition",
            model="MediaTek-Research/Breeze-ASR-25",
            device=0 if torch.cuda.is_available() else "cpu",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            return_timestamps=True
        )
        print("   âœ… Breeze-ASR-25 è¼‰å…¥æˆåŠŸ")
        return model
    except Exception as e:
        print(f"   âŒ Breeze-ASR-25 è¼‰å…¥å¤±æ•—: {e}")
        return None

def create_test_audio():
    """å‰µå»ºæ¸¬è©¦éŸ³è¨Šæª”æ¡ˆï¼ˆ15ç§’ï¼‰"""
    print("ğŸµ å‰µå»ºæ¸¬è©¦éŸ³è¨Šæª”æ¡ˆ:")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ source.aac
    if os.path.exists("source.aac"):
        print("   æ‰¾åˆ° source.aacï¼Œæå–å‰ 15 ç§’ä½œç‚ºæ¸¬è©¦")
        cmd = [
            'ffmpeg', '-i', 'source.aac', 
            '-t', '15',  # åªå–å‰ 15 ç§’
            '-ar', '16000',  # 16kHz
            '-ac', '1',      # å–®è²é“
            '-y', 'test_audio.wav'
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print("   âœ… æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆå‰µå»ºæˆåŠŸ: test_audio.wav")
            return "test_audio.wav"
        else:
            print(f"   âŒ æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆå‰µå»ºå¤±æ•—: {result.stderr}")
            return None
    else:
        print("   âŒ æ‰¾ä¸åˆ° source.aac æª”æ¡ˆ")
        return None

def test_transcription(model, audio_file):
    """æ¸¬è©¦è½‰éŒ„åŠŸèƒ½"""
    print("ğŸ¯ è½‰éŒ„æ¸¬è©¦:")
    try:
        print(f"   è½‰éŒ„æª”æ¡ˆ: {audio_file}")
        result = model(audio_file, return_timestamps=True)
        
        print(f"   è½‰éŒ„çµæœ: {result}")
        
        if 'text' in result:
            text = result['text'].strip()
            print(f"   è½‰éŒ„æ–‡å­—: '{text}'")
            print(f"   æ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")
            
            if text and text != '!' and len(text) > 2:
                print("   âœ… è½‰éŒ„æˆåŠŸï¼")
                return True
            else:
                print("   âš ï¸  è½‰éŒ„çµæœç•°å¸¸ï¼ˆåªæœ‰é©šå˜†è™Ÿæˆ–å¤ªçŸ­ï¼‰")
                return False
        else:
            print("   âŒ è½‰éŒ„çµæœæ ¼å¼éŒ¯èª¤")
            return False
            
    except Exception as e:
        print(f"   âŒ è½‰éŒ„å¤±æ•—: {e}")
        return False

def main():
    print("ğŸš€ é–‹å§‹è½‰éŒ„åŠŸèƒ½æ¸¬è©¦")
    print("=" * 50)
    
    # 1. æ¸¬è©¦ç¡¬é«”
    test_hardware()
    
    # 2. æ¸¬è©¦æ¨¡å‹è¼‰å…¥
    model = test_model_loading()
    if not model:
        print("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒæ¸¬è©¦")
        return
    
    # 3. å‰µå»ºæ¸¬è©¦éŸ³è¨Š
    audio_file = create_test_audio()
    if not audio_file:
        print("âŒ ç„¡æ³•å‰µå»ºæ¸¬è©¦éŸ³è¨Šï¼Œç„¡æ³•ç¹¼çºŒæ¸¬è©¦")
        return
    
    # 4. æ¸¬è©¦è½‰éŒ„
    success = test_transcription(model, audio_file)
    
    print("=" * 50)
    if success:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼è½‰éŒ„åŠŸèƒ½æ­£å¸¸")
    else:
        print("âŒ è½‰éŒ„æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥å•é¡Œ")
    
    # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
    if os.path.exists("test_audio.wav"):
        os.remove("test_audio.wav")
        print("ğŸ—‘ï¸  å·²æ¸…ç†æ¸¬è©¦æª”æ¡ˆ")

if __name__ == "__main__":
    main()
